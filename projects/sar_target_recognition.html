<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Self-Supervised Learning for SAR Target Recognition with Multi-Task Pretext Training | Md Al Siam </title> <meta name="author" content="Md Al Siam"> <meta name="description" content="We developed a self-supervised learning framework for Synthetic Aperture Radar (SAR) Automatic Target Recognition that eliminates dependency on synthetic data while achieving superior performance. Our framework utilizes multi-task pretext training with nine complementary transformation tasks to develop robust feature representations from measured SAR data. The experimental findings demonstrate competitive performance with 89.78% accuracy using SVM classifier and robust detection capabilities even with limited training data, outperforming traditional methods that rely on synthetic data augmentation. This work establishes a foundation for leveraging self-supervised learning in domain-specific applications with limited labeled data."> <meta name="keywords" content="graduate, intern, machine-learning, AI, NLP, CV, research, scientist, PhD, MSc, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://mdalsiam.github.io/projects/sar_target_recognition.html"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Md Al <span class="font-weight-bold">Siam</span> </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">more </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Self-Supervised Learning for SAR Target Recognition with Multi-Task Pretext Training</h1> <p class="post-description">We developed a self-supervised learning framework for Synthetic Aperture Radar (SAR) Automatic Target Recognition that eliminates dependency on synthetic data while achieving superior performance. Our framework utilizes multi-task pretext training with nine complementary transformation tasks to develop robust feature representations from measured SAR data. The experimental findings demonstrate competitive performance with 89.78% accuracy using SVM classifier and robust detection capabilities even with limited training data, outperforming traditional methods that rely on synthetic data augmentation. This work establishes a foundation for leveraging self-supervised learning in domain-specific applications with limited labeled data.</p> </header> <article> <p>We developed a groundbreaking self-supervised learning framework for Synthetic Aperture Radar (SAR) Automatic Target Recognition (ATR) that eliminates the dependency on synthetic data while achieving superior performance. This research addresses critical limitations in SAR target recognition by leveraging multi-task pretext training to learn robust feature representations directly from measured SAR data.</p> <h3 id="research-problem-addressed">Research Problem Addressed</h3> <p>SAR Automatic Target Recognition faces two major obstacles:</p> <ul> <li> <strong>Scarcity of labeled data</strong> due to complex operational conditions</li> <li> <strong>Persistent domain gaps</strong> between synthetic and measured imagery that limit ATR performance</li> </ul> <p>Our framework fundamentally eliminates the need for synthetic data augmentation while achieving <strong>state-of-the-art performance</strong> with significantly reduced training data requirements.</p> <h3 id="our-approach">Our Approach</h3> <p>Unlike traditional methods that rely on synthetic data to bridge training gaps, our self-supervised learning framework learns robust representations directly from measured SAR data through innovative multi-task pretext training.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/sar_recognition-480.webp 480w,/assets/img/publication_preview/sar_recognition-800.webp 800w,/assets/img/publication_preview/sar_recognition-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/publication_preview/sar_recognition.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="SAR ATR Framework" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Self-supervised learning framework for SAR target recognition with multi-task pretext training </div> <h3 id="multi-task-pretext-training">Multi-Task Pretext Training</h3> <p>Our framework employs <strong>nine complementary pretext tasks</strong> designed specifically for SAR data characteristics:</p> <ol> <li> <strong>Original Image Preservation</strong> - Maintains fundamental SAR signature characteristics</li> <li> <strong>Multi-Angle Rotation</strong> (90°, 180°, 270°) - Exploits viewpoint-invariant nature</li> <li> <strong>Gaussian Blur</strong> - Simulates varying resolution scenarios</li> <li> <strong>Horizontal/Vertical Flip</strong> - Learns geometric invariances</li> <li> <strong>Advanced Denoising</strong> - Handles inherent SAR speckle noise using BM3D algorithm</li> <li> <strong>Zoom-In Transformation</strong> - Enables multi-scale feature learning</li> </ol> <h3 id="specialized-cnn-architecture">Specialized CNN Architecture</h3> <ul> <li> <strong>Four convolutional blocks</strong> (32, 64, 128, 256 filters)</li> <li> <strong>Batch normalization</strong> for training stability</li> <li> <strong>Strategic dropout</strong> (0.5) for robust generalization</li> <li> <strong>512-unit dense embedding</strong> space for feature extraction</li> </ul> <h2 id="experimental-validation">Experimental Validation</h2> <div class="row"> <div class="col-sm-6 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5-480.webp 480w,/assets/img/5-800.webp 800w,/assets/img/5-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Performance Results" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-6 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/6-480.webp 480w,/assets/img/6-800.webp 800w,/assets/img/6-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/6.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Comparison Chart" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Performance validation results and comparison with existing methods (placeholder images) </div> <h3 id="sample-dataset-evaluation">SAMPLE Dataset Evaluation</h3> <p>We extensively evaluated our framework on the <strong>Synthetic and Measured Paired and Labeled Experiment (SAMPLE)</strong> dataset containing:</p> <ul> <li><strong>10 distinct military vehicles</strong></li> <li><strong>1,345 measured SAR images</strong></li> <li> <strong>Multiple viewing angles</strong> (10° to 80° azimuth, 14° to 17° elevation)</li> </ul> <h3 id="outstanding-results">Outstanding Results</h3> <h4 id="primary-framework-performance">Primary Framework Performance</h4> <ul> <li> <strong>SVM Classifier</strong>: <strong>89.78%</strong> average accuracy (best performing)</li> <li> <strong>XGBoost</strong>: 81.55% average accuracy</li> <li> <strong>Gradient Boosting</strong>: 80.89% average accuracy</li> <li> <strong>Random Forest</strong>: Competitive performance across all metrics</li> </ul> <h4 id="exceptional-detection-capabilities">Exceptional Detection Capabilities</h4> <ul> <li> <strong>96.64% True Positive Rate</strong> at 5% False Positive Rate</li> <li> <strong>AUC Score</strong>: 0.9934 demonstrating excellent discriminative capability</li> <li> <strong>Robust performance</strong> even with <strong>30% less training data</strong> </li> </ul> <h4 id="lewis-et-al-experimental-adaptation">Lewis et al. Experimental Adaptation</h4> <p>Our SSL adaptation of the original Lewis et al. experiment achieved:</p> <ul> <li> <strong>95.79% accuracy</strong> at k=0.90 (90% measured data)</li> <li> <strong>99.52% TPR</strong> at 5% FPR</li> <li> <strong>Superior performance</strong> without any synthetic data dependency</li> <li> <strong>99.09% accuracy</strong> with full measured data (outperforming original approach)</li> </ul> <h2 id="key-technical-achievements">Key Technical Achievements</h2> <h3 id="synthetic-data-independence">Synthetic Data Independence</h3> <ul> <li> <strong>Eliminated reliance</strong> on synthetic SAR data completely</li> <li> <strong>Addressed domain gap</strong> issues that plague traditional approaches</li> <li> <strong>Direct learning</strong> from measured data preserves real-world phenomenology</li> </ul> <h3 id="data-efficiency">Data Efficiency</h3> <ul> <li> <strong>68.4% of available measured data</strong> used for training (920 images total)</li> <li> <strong>Competitive performance</strong> with significantly reduced data requirements</li> <li> <strong>Robust generalization</strong> across diverse operational conditions</li> </ul> <h3 id="multi-classifier-validation">Multi-Classifier Validation</h3> <p>Comprehensive evaluation across multiple downstream classifiers:</p> <ul> <li> <strong>Support Vector Machine</strong> (Linear kernel)</li> <li> <strong>XGBoost</strong> (100 estimators)</li> <li> <strong>Random Forest</strong> (100 estimators)</li> <li> <strong>Gradient Boosting</strong> (100 estimators)</li> </ul> <h2 id="real-world-applications">Real-World Applications</h2> <div class="row"> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/7-480.webp 480w,/assets/img/7-800.webp 800w,/assets/img/7-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/7.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Military Applications" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/8-480.webp 480w,/assets/img/8-800.webp 800w,/assets/img/8-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/8.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Surveillance Systems" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/9-480.webp 480w,/assets/img/9-800.webp 800w,/assets/img/9-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/9.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Autonomous Systems" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Real-world applications in military, surveillance, and autonomous systems (placeholder images) </div> <h3 id="military--defense">Military &amp; Defense</h3> <ul> <li> <strong>Autonomous target recognition</strong> for unmanned systems</li> <li> <strong>Real-time surveillance</strong> with minimal false alarms</li> <li> <strong>Multi-platform integration</strong> across various SAR sensors</li> <li> <strong>Battlefield intelligence</strong> with reliable target identification</li> </ul> <h3 id="civilian-applications">Civilian Applications</h3> <ul> <li> <strong>Maritime monitoring</strong> for ship detection and classification</li> <li> <strong>Infrastructure monitoring</strong> using satellite SAR data</li> <li> <strong>Environmental surveillance</strong> for change detection</li> <li> <strong>Disaster response</strong> with rapid target assessment</li> </ul> <h2 id="research-significance">Research Significance</h2> <h3 id="academic-impact">Academic Impact</h3> <ul> <li> <strong>Novel SSL framework</strong> specifically designed for SAR domain</li> <li> <strong>Eliminates synthetic data dependency</strong> - a persistent challenge in SAR ATR</li> <li> <strong>Comprehensive evaluation</strong> methodology for domain-specific SSL</li> <li> <strong>Foundation for future research</strong> in radar-based computer vision</li> </ul> <h3 id="technical-advancement">Technical Advancement</h3> <ul> <li> <strong>Multi-task pretext learning</strong> adapted for SAR phenomenology</li> <li> <strong>State-of-the-art performance</strong> with reduced computational requirements</li> <li> <strong>Robust feature representations</strong> generalizing across operational conditions</li> <li> <strong>Practical deployment</strong> ready for real-world SAR systems</li> </ul> <h2 id="future-research-directions">Future Research Directions</h2> <h3 id="enhanced-ssl-techniques">Enhanced SSL Techniques</h3> <ul> <li> <strong>Additional domain-specific pretext tasks</strong> (frequency simulation, viewing angle modeling)</li> <li> <strong>Contrastive learning</strong> approaches for SAR data</li> <li> <strong>Multi-modal SSL</strong> incorporating radar and optical data</li> <li> <strong>Temporal sequence modeling</strong> for moving target recognition</li> </ul> <h3 id="system-integration">System Integration</h3> <ul> <li> <strong>Real-time processing</strong> optimization for operational systems</li> <li> <strong>Edge deployment</strong> for resource-constrained platforms</li> <li> <strong>Federated learning</strong> across distributed SAR networks</li> <li> <strong>Adversarial robustness</strong> for hostile environments</li> </ul> <h2 id="technical-specifications">Technical Specifications</h2> <ul> <li> <strong>Framework</strong>: TensorFlow/Keras with custom SSL pipeline</li> <li> <strong>Input Resolution</strong>: 128×128 grayscale SAR images</li> <li> <strong>Training Strategy</strong>: Multi-task pretext learning with 9 complementary tasks</li> <li> <strong>Feature Dimension</strong>: 512-dimensional embedding space</li> <li> <strong>Optimization</strong>: Adam optimizer with early stopping</li> <li> <strong>Evaluation</strong>: 5-fold cross-validation with held-out test sets</li> </ul> <h2 id="code--reproducibility">Code &amp; Reproducibility</h2> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/10-480.webp 480w,/assets/img/10-800.webp 800w,/assets/img/10-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/10.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Code Repository" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Open-source implementation available for research community (placeholder image) </div> <h3 id="open-source-implementation">Open Source Implementation</h3> <ul> <li> <strong>Complete codebase</strong> available on GitHub</li> <li> <strong>Reproducible experiments</strong> with detailed documentation</li> <li> <strong>Pre-trained models</strong> for immediate deployment</li> <li> <strong>Comprehensive evaluation scripts</strong> for benchmark comparisons</li> </ul> <hr> <p><em>This research was conducted at Tuskegee University’s ECE Department with support from the National Science Foundation and DoD OUSD (R&amp;E) under Cooperative Agreement PHY-2229929 (The NSF AI Institute for Artificial and Natural Intelligence). This work represents a significant breakthrough in SAR target recognition and establishes new paradigms for self-supervised learning in radar applications.</em></p> <h3 id="research-impact">Research Impact</h3> <p>This framework not only advances the state of SAR target recognition but also establishes a foundation for leveraging self-supervised learning in other domain-specific applications with limited labeled data, opening new research avenues in radar-based computer vision and autonomous systems.</p> </article> <div id="giscus_thread" style="max-width: 1000px; margin: 0 auto;"> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'MdAlSiam/mdalsiam.github.io',
        'data-repo-id': '',
        'data-category': 'Comments',
        'data-category-id': '',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Md Al Siam. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Last updated: June 30, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>